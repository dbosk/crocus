\section{Discussion}%
\label{Discussion}

\subsection{Assumptions limitations} 

Some of the assumptions that are required for implementing our proposition are 
not yet realized, however, we believe that they will soon be realized.

One major issue is that all protesters must have smartphones --- in many 
countries with oppressive regimes, far from all possess smartphones
currently, though it is on the rise.

On those smartphones we additionally require digital certificates signed by 
some \ac{CA}.
This is also not yet widely available.
However, more and more states are starting to issue digital certificates in 
identity cards and many already have crypto-enabled RFID chips in their 
passports.
\Eg Estonia, Germany, and Sweden already have the infrastructure and widely 
deployed electronic identity systems, and the EU already has regulation in 
place (eIDAS).
The speed of adoption will depend on the architecture of these systems.
For instance, the system used in Sweden (BankID) is implemented in software 
(most use it on smartphones) and can thus easily be upgraded to include the 
anonymous credentials that \CROCUS needs.
As for wide deployment: more than \SI{95}{\%} of people in the ages 21--50 uses 
it, \SI{88}{\%} for ages 51--60 and \SI{76}{\%} for ages 61--70\footnote{%
  Official statistics, in Swedish:  
  \url{https://www.bankid.com/assets/bankid/stats/2018/statistik-2018-04.pdf}.
}.

We also need to run distance-bounding protocols on smartphones.
Achieving distance-bounding protocols on smartphones is currently not feasible 
within a meaningful range of distance.
Indeed, existing smartphones lack the required hardware to conduct the distance 
bounding fast enough.
However, thefts of luxury cars due to relay attacks have driven the development 
of hardware for doing distance bounding in car keys.
We believe that using smartphones for contactless payment and electronic 
tickets will drive a similar development for this hardware on smartphones.


\subsection{Mobile ad-hoc networks}

\input{MANETs.tex}


\subsection{The adversaries}

Our adversary model considers only protocol data, no auxiliary data.
And against this adversary our scheme is secure.
The question is how this adversary model maps to real adversaries.

In any real implementation there are potential side-channels.
\Eg in the communication layer: IP-addresses translate into identities, 
devices' MAC-addresses can be used as persistent identifiers.
We do not consider these aspects as there are entire fields dedicated to some 
of them, we simply assume the tools developed in those fields (\eg 
Tor~\cite{Tor} and randomized MAC-addresses) to prevent these problems will be 
used.
And even if the adversary would be a nation state that controls all the 
nation's \acp{ISP}, we do not consider it realistic that such an adversary can 
do \eg time-correlation attacks against citizens that submit transactions over 
Tor.
If they could, that would mean that the honestly-but-curiously controlled 
\(\TS\) would learn the identity for each submission and, thus, the adversary 
could link the identity to a particular \(\cid\).
However, this is possible for a global, passive adversary, but the nation state 
in question cannot observe all input to \(\TS\).

During a protest there are also other information channels available to the 
adversary.
\Eg, one could argue that the adversary might be able to map a face to a 
\(\pid\) by means of signal triangulation during the protocol run.
(And then map the face to an identity through face recognition.)
However, there are far easier tactics the adversary could use: \eg, the 
adversary can take photos of the event and try to capture as many faces as 
possible.
This is already possible today and, thus, not a weakness introduced by our 
scheme.


\subsection{Receipt freeness, Sybil and issuing keys}

We need an anonymous identity credential that provides unlinkability between 
contexts but linkability for reuse within the same context.
The linkability within contexts interferes with receipt freeness: an adversary 
can reuse the credential within the same context, then the linkability property 
will provide a verification mechanism.
Conversely, if we provide receipt freeness, then the absence of linkability 
will allow Sybil attacks.
This is different from voting where the organizers note participation to 
prevent voting twice, but provides receipt freeness for the actual ballot.
In our case, participation and the ballot are the same.

Each issued anonymous identity credential is essentially a pseudonym.
This means that if a person is issued two credentials, she has two pseudonyms 
and could participate twice everywhere without detection.
This means that federated identity-management is not suitable to handle 
anonymous identity credentials.
Indeed, it works for non-anonymous identities: one agency may issue passports 
and another one driver licenses.
But if one issues an anonymous identity credential to Alice, the other must 
not.
However, this is easily solved by collective signing~\cite{collective-signing}, 
which likely is not far away with the current pace for adopting public ledgers.
We see this as a likely extension to EU's eIDAS regulation.


%\subsection{Other actors}
%
%Without verifiable binding to a location, even distance-bounding protocols do not prevent collusions such as protesters meeting at a safe location away from the official site. 
%To address that, one can use trusted infrastructure (for an example by media see~\cite{LeMondeProtestingSolution}) or people such as journalists. 
%Given the conflict of interest of potentially state-provided infrastructure for political protests, we opt for the trusted journalist, Jane, who reveals her identity after the protest and thus can be used as a trusted witness. 
%In practice, there can be any number of  Janes and, as with the different ways of counting, there does not need to be an agreement on who is trusted as anyone can set the eligibility criteria for their count.
%
%Finally, Mallory represents another nation state and has some interest in affecting the stability of Grace's regime, for Mallory's own gain, thus supporting either Grace or Alice as she see fits.  
%Thus, the objective of Mallory will also be to either increase or decrease the count. 
%Unlike Alice, Mallory can create as many keys as she likes, but she cannot create keys valid in another nation state. 
%Nonetheless, Mallory could also have simply as her objective to cause a denial-of-service attack on the architecture of \CROCUS.
%

%\subsection{Trust assumptions}
%
%The goal of CROCUS is to be able to count people in a crowd in a verifiable way, without leaking information about the individuals in the crowd.
%We believe one of the strongest adversaries in practice, and one of the most dangerous situation, is that of an authoritarian government wanting to learn the identities of protesters,
%so we chose a theoretical model that fits this situation well, but it is interesting to see what are the trust relations which are actually needed in various real world situations.
%
%\paragraph{ID issuer} We assumed a trusted third party issued certified IDs to every participant (protesters and witnesses). This hypothesis is important to avoid Sybil attacks,
%but only the side protesting (not the side being protested against) has an incentive to perform a Sybil attack.
%So in practice, the ID issuer doesn't need to be a trusted 3rd-party, it only needs to not be aligned with the protesters.
%In our authoritarian government scenario for instance, the protesters can use IDs issued by said government.
%On the other hand however, a pro-government protest cannot use the same IDs and offer a good level of trust in the final count, and it would be better suited to use IDs from a different source
%(\eg a supra-national issuer like the EU).
%
% \paragraph{Verifier's trust in the count} We proposed a generic way of counting, that relies on two parameters: the strength function and the threshold.
%%We then suggested two possible instantiations: every witness is equal and we use a relatively large threshold, or we only trust a minority of independent witnesses with a threshold of 1.
%An important point here is that these parameters can be chosen by each verifier independently, so each verifier can make choices that satisfy \emph{their} own level of trust, and can each obtain a different final count, and \CROCUS does not output one definitive answer. The trust in a final count depends only on the trust between the verifier and the witnesses.
%
%\simon{maybe delete that second half}
%In practice though, the verifier can be in either of three situations: for the protest, against the protest, or indifferent, which leads to three main categories of choices.
%\begin{itemize}
%	\item A verifier aligned with the protesters has an incentive to trust any witness and use as low a threshold as possible.
%	\item A verifier opposed to the protesters has the opposite incentive to exclude as many witnesses and use as high a threshold as possible.
%	\item An indifferent verifier who only cares about the correctness of the result can trust each witness based on their reputation and should use a threshold that is reasonably reachable in practice but high enough to avoid small-scale collusion.
%\end{itemize}
%
%\paragraph{Protesters and witnesses} Active participants in a protest do not need to trust anything other than that their app is behaving properly and that their smartphone is not compromised. Indeed, \CROCUS has been designed with their privacy and security as a central concern, and being able to use \CROCUS without any additional risk compared to simply come at the protest was one of our main requirement.
