\subsection{Privacy adversary}%
\label{adversary-model-different-levels}

We provide one system model with two possible adversaries: one who tries to link a protester's real identity (\(P\)) to a protest proof-share (\(\cid\)) and one 
that aims at linking a protester's or a witness's real identity (\(P\), respectively \(W\)), to a location (\(l\)).
We also define varying strengths of each adversary.

\paragraph{The identity--proof share linking adversary}

There are three players: the protest participant (with identity) \(P\), a witness (with identity) \(W\) and the storage \(S\).
The adversary \(A\) controls \(W\) and \(S\).

\begin{definition}[Base identity--proof share adversary]%
  \label{base-identity-proof-share-adversary}
  The protester \(P\) and the witness \(W\) communicate.
  Each learns only the protocol data \(d_{P,W}(\cid, P)\) and when it happened 
  \(t_{P,W}\)\footnote{%
    Specifically, they do \emph{not} learn the real identities \(P\) and \(W\) 
    directly, only if those appear in the data \(d_{P,W}(\cid, P)\).
  }.
  The protester \(P\) communicates with \(S\), in which \(S\) only learns 
  \(f(d_{P,W}(\cid, P))\), for some function \(f\), and the time of the 
  communication (\(t_{P,S}\)) but not the real identities.
  The adversary controls \(W\) and \(S\) and thus learns everything that they 
  do, but can additionally correlate what he learns from \(W\) and \(S\).
\end{definition}

This definition is illustrated in \cref{fig:identity-proof-share-adversary}.

\begin{figure}
  \centering
  \includegraphics{base-identity-proof-share-adversary.tikz}
  \caption{\label{fig:identity-proof-share-adversary}%
    An overview of the base identity--proof share adversary model.
    The protester with real identity \(P\) and witness with real identity \(W\) 
    communicate and each learn only the protocol data, \(d_{P,W}(\cid, P)\), 
    and the time it happened, \(t_{P,W}\).
    The protester submits \(f(d_{P,W}(\cid, P))\), for some function \(f\), to 
    the storage \(S\), who learns only that and the time it happened, 
    \(t_{P,S}\).
    Both the witness \(W\) and storage \(S\) are controlled by the adversary 
    \(A\).
  }
\end{figure}

We find \cref{base-identity-proof-share-adversary} suitable when the protester and witness both move in a crowd and there is no way for the witness to decide exactly with whom he or she communicates with.
However, in some situations this might not be the case, \eg the crowd is not dense.
In these situations the witness will likely see the face of the protester.
We capture this by the following definition.

\begin{definition}[Stronger identity--proof share adversary]%
  \label{stronger-identity-proof-share-adversary}
  The situation is the same as in \cref{base-identity-proof-share-adversary}, but now the 
  witness \(W\) learns the protester \(P\)'s identity.
  (\(P\) will also learn \(W\)'s identity.)
  However, \(S\) still does not learn \(P\)'s identity.
\end{definition}

One reason to not allow \(S\) to learn \(P\)'s identity is that for this communication \(P\) has options, such as Tor~\cite{Tor}, for anonymous communication.
However, given a strong enough adversary, such anonymous communication might not be possible.
We capture such a strong adversary in the following definition.

\begin{definition}[Strongest identity--proof share adversary]%
  \label{strongest-identity-proof-share-adversary}
  Everything is the same as in \cref{stronger-identity-proof-share-adversary}, except that now \(S\) also learns \(P\)'s identity.
\end{definition}

